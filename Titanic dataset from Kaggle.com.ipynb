{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is my work on Titanic dataset from kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for data visualization and preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So the plan is visualize and preprocess data from train set and do same preprocessing to test set. Then train different machine learning models on training test, pick the best two (competition uses accuracy score as evaluation so that's what I'm going to us as well), try to tune them a bit hoping to get a better score, use the best one on test set and submit the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# check general info on the datasets\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Cabin\" columns in both train and test datasets have too many values missing. I will just drop them out. \n",
    "### \"SibSP\" and \"Parch\" columns basically show family members travelling with the passenger so I'll create column \"Family\" instead of them with 0s if no family members were on board and 1s if there were any family member. Then I'll drop \"SibSP\" and \"Parch\" columns as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column Family using list comprehention\n",
    "train[\"Family\"] = [0 if train[\"SibSp\"][i] == 0 and train[\"Parch\"][i] == 0 else 1 for i in range(len(train[\"Parch\"]))]\n",
    "test[\"Family\"] = [0 if test[\"SibSp\"][i] == 0 and test[\"Parch\"][i] == 0 else 1 for i in range(len(test[\"Parch\"]))]\n",
    "\n",
    "# dropping columns out\n",
    "train.drop([\"Cabin\",\"SibSp\",\"Parch\"], axis=1, inplace=True)\n",
    "test.drop([\"Cabin\",\"SibSp\",\"Parch\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I need to deal with missing values.\n",
    "### \"Embarked\" column on train set has only two values missing. I think I can fill it with the most popular port of embarkment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Embarked', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# countplot to find out which port was the most popular to embark from\n",
    "sns.countplot(train[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to the graph it would be pretty safe to put Southampton as port of embarkment instead of two missing values as it was by far the most popular embarkment spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Embarked\"].fillna(\"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to the \"Age\" column. \n",
    "### Normally, I would put mean age values instead of missing ones. But in this case I'll try it a little bit different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age in train dataset is 29.69911764705882 years old\n",
      "Mean age in test dataset is 30.272590361445783 years old\n"
     ]
    }
   ],
   "source": [
    "# mean age\n",
    "train_meanage = train[\"Age\"].mean()\n",
    "test_meanage = test[\"Age\"].mean()\n",
    "print(f\"Mean age in train dataset is {train_meanage} years old\")\n",
    "print(f\"Mean age in test dataset is {test_meanage} years old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So the mean age is around 30 years but this number is a bit different for different classes. The idea is that people of the 1st class were probably older than people of the 2nd or 3rd class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    38.233441\n",
       "2    29.877630\n",
       "3    25.140620\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Age\"].groupby(train[\"Pclass\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    40.918367\n",
       "2    28.777500\n",
       "3    24.027945\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Age\"].groupby(test[\"Pclass\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's true! People in the 1st class were older than of the 2nd and the 3rd class. Let's write a function so we could fill in the blanks accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_age_train(age_pclass):     # a function would take two columns (\"Age\" and \"Pclass\") as parameters\n",
    "    \n",
    "    age = age_pclass[0]\n",
    "    pclass = age_pclass[1]\n",
    "    \n",
    "    # if the value is missing\n",
    "    if pd.isnull(age):\n",
    "        \n",
    "        # if 1st class\n",
    "        if pclass == 1:\n",
    "            return 38\n",
    "        \n",
    "        # if 2nd class\n",
    "        elif pclass == 2:\n",
    "            return 30\n",
    "        \n",
    "        # if 3rd class\n",
    "        else:\n",
    "            return 25\n",
    "        \n",
    "    # if no values missing    \n",
    "    else:\n",
    "        return age\n",
    "    \n",
    "    \n",
    "# and almost the same for test set\n",
    "def mean_age_test(age_pclass):     # a function would take two columns (\"Age\" and \"Pclass\") as parameters\n",
    "    \n",
    "    age = age_pclass[0]\n",
    "    pclass = age_pclass[1]\n",
    "    \n",
    "    # if the value is missing\n",
    "    if pd.isnull(age):\n",
    "        \n",
    "        # if 1st class\n",
    "        if pclass == 1:\n",
    "            return 41\n",
    "        \n",
    "        # if 2nd class\n",
    "        elif pclass == 2:\n",
    "            return 29\n",
    "        \n",
    "        # if 3rd class\n",
    "        else:\n",
    "            return 24\n",
    "        \n",
    "    # if no values missing    \n",
    "    else:\n",
    "        return age\n",
    "    \n",
    "    \n",
    "# now applying those functions\n",
    "train[\"Age\"] = train[[\"Age\",\"Pclass\"]].apply(mean_age_train, axis=1)\n",
    "test[\"Age\"] = test[[\"Age\",\"Pclass\"]].apply(mean_age_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now there is only one missing values left in \"Fare\" column of test dataset. I think I'll same technique as I used for \"Age\" column. Put a mean value according to the class instead of missing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    94.280297\n",
       "2    22.202104\n",
       "3    12.459678\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean fare values grouped by class\n",
    "test[\"Fare\"].groupby(test[\"Pclass\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>60.5</td>\n",
       "      <td>3701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                Name   Sex   Age Ticket  Fare  \\\n",
       "152         1044       3  Storey, Mr. Thomas  male  60.5   3701   NaN   \n",
       "\n",
       "    Embarked  Family  \n",
       "152        S       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what class the passenger with missing value in \"Fare\" column used\n",
    "test[test[\"Fare\"].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so this person used the 3rd class\n",
    "test[\"Fare\"].fillna(12.46, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out our datasets again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   Ticket       891 non-null    object \n",
      " 7   Fare         891 non-null    float64\n",
      " 8   Embarked     891 non-null    object \n",
      " 9   Family       891 non-null    int64  \n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          418 non-null    float64\n",
      " 5   Ticket       418 non-null    object \n",
      " 6   Fare         418 non-null    float64\n",
      " 7   Embarked     418 non-null    object \n",
      " 8   Family       418 non-null    int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 29.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No missing values - good!\n",
    "### Now I'll drop out several columns. \"PassangerId\" - no use in that, \"Name\" - I could get titles out of that but I don't see how that would be usefull. We already have \"Sex\" column and I feel like titles and sex will be to similar. \"Ticket\" - same thing. I think it would be too similar to \"Pclass\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the columns mentioned above out\n",
    "train.drop([\"PassengerId\",\"Name\",\"Ticket\"], axis=1, inplace=True)\n",
    "test.drop([\"PassengerId\",\"Name\",\"Ticket\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize survival rate by different sexes, classes, embarkment ports and those who had relatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Family', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,6), sharey=True)\n",
    "sns.countplot(x=\"Sex\", hue=\"Survived\", data=train, ax=axes[0][0])\n",
    "sns.countplot(x=\"Pclass\", hue=\"Survived\", data=train, ax=axes[0][1])\n",
    "sns.countplot(x=\"Embarked\", hue=\"Survived\", data=train, ax=axes[1][0])\n",
    "sns.countplot(x=\"Family\", hue=\"Survived\", data=train, ax=axes[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to the graphs, we can see that there were 2,5 times more females survived than males(females were one of the first ones to board lifeboats), more than half of passengers of the 1st class survived (they occupied top decks of the ship). Most of the dead and survived embarked in Southampton (makes sense considering it was the most popular port of embarkment) and half of those who had family members on board survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I think it's all set for machine learning part now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the features we're working with again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       891 non-null    float64\n",
      " 4   Fare      891 non-null    float64\n",
      " 5   Embarked  891 non-null    object \n",
      " 6   Family    891 non-null    int64  \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 48.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    object \n",
      " 2   Age       418 non-null    float64\n",
      " 3   Fare      418 non-null    float64\n",
      " 4   Embarked  418 non-null    object \n",
      " 5   Family    418 non-null    int64  \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 19.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, I'll have to convert categorical data (\"Embarked\" and \"Sex\" columns) into numerical, scale the data. I want to use cross validation with accuracy score as evaluation metric. Also I'll try different machine learning techniques for classification (logistic regression, decision tree, random forest, knn, support vector machines, adaptive boosting and extreme gradient boosting). Then I'll do grid search for tuning top 2 models trying to get them to perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and variables for ml\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # for labeling and scaling\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression()\n",
    "\n",
    "# knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# support vector machines\n",
    "from sklearn.svm import SVC\n",
    "sv = SVC()\n",
    "\n",
    "# adaptive boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaboost = AdaBoostClassifier(base_estimator=dtree)\n",
    "\n",
    "# extreme gradient boosting\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label and scale data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into X and y\n",
    "X = train.drop(\"Survived\", axis=1)\n",
    "y = train[\"Survived\"]\n",
    "\n",
    "# labeling\n",
    "columns = [\"Sex\",\"Embarked\"]\n",
    "for column in columns:\n",
    "    X[column] = LabelEncoder().fit_transform(X[column])\n",
    "    test[column] = LabelEncoder().fit_transform(test[column])\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to use a for loop to train every model and print out mean accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression's mean accuracy score is 0.7901498127340825\n",
      "K-Nearest Neighbors's mean accuracy score is 0.802521847690387\n",
      "Decision tree's mean accuracy score is 0.7890886392009987\n",
      "Random forest's mean accuracy score is 0.8070287141073658\n",
      "Support Vector Machines's mean accuracy score is 0.8125468164794007\n",
      "Adaptive boosting's mean accuracy score is 0.802521847690387\n",
      "Extreme gradient boosting's mean accuracy score is 0.8126342072409487\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic regression\":logr,\n",
    "    \"K-Nearest Neighbors\":knn,\n",
    "    \"Decision tree\":dtree,\n",
    "    \"Random forest\":rfc,\n",
    "    \"Support Vector Machines\":sv,\n",
    "    \"Adaptive boosting\":adaboost,\n",
    "    \"Extreme gradient boosting\":xgb\n",
    "}\n",
    "\n",
    "for variable, model in models.items():\n",
    "    print(f\"{variable}'s mean accuracy score is {cross_val_score(model, X, y, cv=10, scoring='accuracy').mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So the best two are XGBoost and Support vector machines. But Support vector machines is very slow (Seriously, I tried to tune it once and it took way too much time for almost no improvement) so I think I'll use XGBoost and Random forest this time.\n",
    "### I want to try to tune them to see if I can make them perform better. Using Grid search for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.8395630461922596\n",
      "Best parameters are {'gamma': 0.001, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# start with xgboost parameters\n",
    "xgb_params = {\n",
    "    \n",
    "    \"learning_rate\":[1,0.1,0.01,0.001],\n",
    "    \"n_estimators\":[100,150,300,600,1000],\n",
    "    \"max_depth\":range(3,10,2),\n",
    "    \"min_child_weight\":range(1,6,2),\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator=XGBClassifier(),\n",
    "                       param_grid=xgb_params,\n",
    "                       cv=10, scoring=\"accuracy\")\n",
    "xgb_grid.fit(X,y)\n",
    "\n",
    "# best score and parameters\n",
    "print(f\"Best score is {xgb_grid.best_score_}\")\n",
    "print(f\"Best parameters are {xgb_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.8373033707865168\n",
      "Best parameters are {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# and random forest\n",
    "rfc_params = {\n",
    "    \"criterion\":[\"gini\",\"entropy\"],\n",
    "    \"n_estimators\":[100,150,300,600,1000],\n",
    "    \"max_depth\":[None,10,20,30,40,50,60,70,80,90,100],\n",
    "    \"min_samples_leaf\":[1,2,4],\n",
    "    \"min_samples_split\":[2,5,10],\n",
    "    \"max_features\":[\"auto\",\"sqrt\",\"log2\"],\n",
    "    \"bootstrap\":[True,False]\n",
    "}\n",
    "\n",
    "rfc_grid = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                       param_grid=rfc_params,\n",
    "                       cv=10, scoring=\"accuracy\")\n",
    "rfc_grid.fit(X,y)\n",
    "\n",
    "# best score and parameters\n",
    "print(f\"Best score is {rfc_grid.best_score_}\")\n",
    "print(f\"Best parameters are {rfc_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's good I didn't hold my breath for that. Took a bit of a time :-)\n",
    "### Now I'll set XGBoost with optimal parameters and do predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_xgb = XGBClassifier(gamma=0.001,\n",
    "                       learning_rate=0.1,\n",
    "                       max_depth=5,\n",
    "                       min_child_weight=5,\n",
    "                       n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.001, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=300, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "opt_xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predict = opt_xgb.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I should've saved \"PassengerID\" column from the test data set for submission. Now, I'll have to read .csv file again, then I'll take that column and concat it with predictions and save the new dataframe into submission.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test.csv again\n",
    "for_submission = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# predictions into dataframe\n",
    "prediction_df = pd.DataFrame(data=predict, columns=[\"Survived\"])\n",
    "\n",
    "# submission dataframe\n",
    "submission = pd.concat([for_submission[\"PassengerId\"], prediction_df], axis=1)\n",
    "\n",
    "# submission dataframe into .csv file\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file was submitted to kaggle.com with the score of 0.76315 which I think a decent result for my first competition!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any tips, hints, ideas, etc. to improve the score are very welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS \n",
    "### I decided to submit predictions of the tuned random forest as well. The result turned out to be slightly better - 0.77990. But I still think Extreme gradient boosting would be a better option because it took much less time tunning it than Random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters for random forest\n",
    "opt_rfc = RandomForestClassifier(criterion=\"entropy\",\n",
    "                                max_features=\"log2\",\n",
    "                                bootstrap=True,\n",
    "                                max_depth=30,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_samples_split=5,\n",
    "                                n_estimators=100)\n",
    "\n",
    "# training the model\n",
    "opt_rfc.fit(X,y)\n",
    "\n",
    "# predictions into dataframe\n",
    "pred = pd.DataFrame(data=opt_rfc.predict(test), columns=[\"Survived\"])\n",
    "\n",
    "# submission dataframe\n",
    "rfc_pred = pd.concat([for_submission[\"PassengerId\"], pred], axis=1)\n",
    "\n",
    "# submission dataframe to .csv file\n",
    "rfc_pred.to_csv(\"rfc_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
